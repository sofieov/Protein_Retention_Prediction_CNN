{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =================== Import ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =================== Variables ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Raw files from UniProt and PROSITE\n",
    "pos_in_prosite = os.path.abspath('1.1.Data_Files/Positives_PROSITE.fasta') \n",
    "pos_in_uniprot = os.path.abspath('1.1.Data_Files/Positives_UniProt.fasta') \n",
    "neg_in = os.path.abspath('1.1.Data_Files/Negatives_UniProt.fasta') \n",
    "\n",
    "# Seperated files\n",
    "pos_out_prosite = os.path.abspath(\"1.2.Sorted_Files/Positives_Modified_PROSITE.fasta\") \n",
    "pos_out_uniprot = os.path.abspath(\"1.2.Sorted_Files/Positives_Modified_UniProt.fasta\") \n",
    "neg_out = os.path.abspath(\"1.2.Sorted_Files/Negatives_Modified_UniProt.fasta\") \n",
    "\n",
    "# Concatenated files\n",
    "conc_prosite = os.path.abspath(\"1.2.Sorted_Files/Conc_PROSITE.fasta\")\n",
    "conc_uniprot = os.path.abspath(\"1.2.Sorted_Files/Conc_UniProt.fasta\")\n",
    "\n",
    "# CD-HIT files\n",
    "cdhit_prosite = os.path.abspath(\"1.3.CD_HIT_Files/CD_HIT_PROSITE.txt\")\n",
    "cdhit_uniprot = os.path.abspath(\"1.3.CD_HIT_Files/CD_HIT_UniProt.txt\")\n",
    "\n",
    "# Cluster files\n",
    "cluster_prosite = os.path.abspath(\"1.4.Cluster_Files/Cluster_PROSITE.fasta\")\n",
    "cluster_uniprot = os.path.abspath(\"1.4.Cluster_Files/Cluster_UniProt.fasta\")\n",
    "\n",
    "# Final files\n",
    "final_prosite = os.path.abspath(\"1.5.Final_Files/Final_PROSITE.fasta\")\n",
    "final_uniprot = os.path.abspath(\"1.5.Final_Files/Final_UniProt.fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =================== Functions ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ModifyPosAndNeg(pos_in_prosite,pos_in_uniprot,neg_in):\n",
    "    '''Function to modify all headers in each fasta file, in order to have the same format in the headings'''   \n",
    "    # Positive PROSITE\n",
    "    pos_prosite = open(pos_in_prosite)\n",
    "    pos_prosite = pos_prosite.read()\n",
    "    index = 0\n",
    "    f = open(pos_out_prosite, 'w')\n",
    "    for line in pos_prosite.splitlines():\n",
    "        if line.startswith('>sp|'):\n",
    "            index += 1\n",
    "            header = line[line.find('>sp|'): line.index('|', line.index('|') + 1)]  +   str('|Positive')\n",
    "            print(header ,file=f)\n",
    "        else:\n",
    "            print(line , file=f)\n",
    "    f.close()    \n",
    "    # Positive UniProt\n",
    "    pos_uniprot = open(pos_in_uniprot)\n",
    "    pos_uniprot = pos_uniprot.read()    \n",
    "    index = 0\n",
    "    f = open(pos_out_uniprot, 'w')\n",
    "    for line in pos_uniprot.splitlines():\n",
    "        if line.startswith('>sp|'):\n",
    "            index += 1\n",
    "            header = line[line.find('>sp|'): line.index('|', line.index('|') + 1)]  +   str('|Positive')\n",
    "            print(header ,file=f)\n",
    "        else:\n",
    "            print(line , file=f)\n",
    "    f.close()    \n",
    "    # Negative\n",
    "    neg_uniprot = open(neg_in)\n",
    "    seq_neg = neg_uniprot.read()    \n",
    "    index = 0 \n",
    "    f = open(neg_out, 'w')\n",
    "    for line in seq_neg.splitlines():\n",
    "        if line.startswith('>sp|'):\n",
    "            index += 1\n",
    "            header = line[line.find('>sp|'): line.index('|', line.index('|') + 1)]   +   str('|Negative')\n",
    "            print(header , file=f)\n",
    "        else:\n",
    "            print(line , file=f)\n",
    "    f.close()   \n",
    "    return pos_out_prosite, pos_out_uniprot, neg_out  \n",
    "\n",
    "\n",
    "\n",
    "def ConcatClusterPosAndNeg(pos_out_prosite,pos_out_uniprot,neg_out,cdhit_prosite,cdhit_uniprot):\n",
    "    '''Function to concatenate each of the two postive fasta files with the negative fasta file.\n",
    "    Furthermore the cluster number is assigned to the concerned protein, where the cluster number is obtained from CD-HIT'''\n",
    "    # Concatenate files with pos(PROSITE) + neg\n",
    "    files_prosite = [pos_out_prosite, neg_out]\n",
    "    with open(conc_prosite, 'w') as outfile_prosite:\n",
    "        for fname_p in files_prosite:\n",
    "            with open(fname_p) as infile_p:\n",
    "                outfile_prosite.write(infile_p.read())               \n",
    "    # Add cluster number to header\n",
    "    cd_prosite = open(cdhit_prosite)\n",
    "    cd_prosite = cd_prosite.read()  \n",
    "    f = open(cluster_prosite, 'w')\n",
    "    for line_cd in cd_prosite.splitlines():  \n",
    "        if line_cd.startswith('>Cluster'): \n",
    "            clusternr = '_' + line_cd[9:]\n",
    "        else:\n",
    "            line = line_cd[line_cd.find('>sp|'): line_cd.find('.')]\n",
    "            print(line + clusternr, file=f)\n",
    "    f.close()             \n",
    "    # Concatenate files with pos(UniProt) + neg\n",
    "    files_uniprot = [pos_out_uniprot, neg_out]\n",
    "    with open(conc_uniprot, 'w') as outfile_uniprot:\n",
    "        for fname_u in files_uniprot:\n",
    "            with open(fname_u) as infile_u:\n",
    "                outfile_uniprot.write(infile_u.read())\n",
    "    # Add cluster number to header\n",
    "    cd_uniprot = open(cdhit_uniprot)\n",
    "    cd_uniprot = cd_uniprot.read()\n",
    "    f = open(cluster_uniprot, 'w')\n",
    "    for line_cd in cd_uniprot.splitlines():  \n",
    "        if line_cd.startswith('>Cluster'): \n",
    "            clusternr = '_' + line_cd[9:]\n",
    "        else:\n",
    "            line = line_cd[line_cd.find('>sp|'): line_cd.find('.')]\n",
    "            print(line + clusternr, file=f)\n",
    "    f.close()       \n",
    "    return conc_prosite, conc_uniprot, cluster_prosite, cluster_uniprot\n",
    "\n",
    "\n",
    "\n",
    "def FinalFiles(conc_prosite,cluster_prosite,conc_uniprot,cluster_uniprot):\n",
    "    '''Function to concatenate the cluster number with the sequence, creating the final file with the desired format'''  \n",
    "    # Final: pos(PROSITE) + neg\n",
    "    concat_prosite = open(conc_prosite)\n",
    "    concat_prosite = concat_prosite.read()\n",
    "    clus_prosite = open(cluster_prosite)\n",
    "    clus_prosite = clus_prosite.read() \n",
    "    f = open(final_prosite, 'w')\n",
    "    for line_conc in concat_prosite.splitlines():\n",
    "        if line_conc.startswith('>sp|'):\n",
    "            for line_clus in clus_prosite.splitlines():\n",
    "                if line_conc[0:18] == line_clus[0:18]:\n",
    "                    print(line_clus, file=f)\n",
    "                    break\n",
    "        else:\n",
    "            print(line_conc, file=f)\n",
    "    f.close( )\n",
    "    # Final: pos(UniProt) + neg\n",
    "    concat_uniprot = open(conc_uniprot)\n",
    "    concat_uniprot = concat_uniprot.read()\n",
    "    clus_uniprot = open(cluster_uniprot)\n",
    "    clus_uniprot = clus_uniprot.read() \n",
    "    f = open(final_uniprot, 'w')\n",
    "    for line_conc in concat_uniprot.splitlines():\n",
    "        if line_conc.startswith('>sp|'):\n",
    "            for line_clus in clus_uniprot.splitlines():\n",
    "                if line_conc[0:18] == line_clus[0:18]:\n",
    "                    print(line_clus, file=f)\n",
    "                    break\n",
    "        else:\n",
    "            print(line_conc, file=f)\n",
    "    f.close( )\n",
    "    return final_prosite, final_uniprot\n",
    "\n",
    "\n",
    "\n",
    "def Similarity(final_prosite,final_uniprot):\n",
    "    '''Functions to determine which positive data set, should be used in the further work'''   \n",
    "    f_prosite = open(final_prosite)\n",
    "    f_prosite = f_prosite.read()\n",
    "    f_uniprot = open(final_uniprot)\n",
    "    f_uniprot = f_uniprot.read()\n",
    "    sameID = []\n",
    "    for line_pro in f_prosite.splitlines():\n",
    "            if line_pro.startswith('>sp|'):\n",
    "                for line_uni in f_uniprot.splitlines():\n",
    "                    if line_pro[0:18] == line_uni[0:18]:\n",
    "                        sameID.append(line_pro[line_pro.find('>sp|'): line_pro.find('_')])                    \n",
    "    return sameID\n",
    "# Counting the amount of proteins in the PROSITE and the UniProt data set\n",
    "def Similarity_prosite(final_prosite,final_uniprot):\n",
    "    f_prosite = open(final_prosite)\n",
    "    f_prosite = f_prosite.read()\n",
    "    sameID_prosite = []\n",
    "    for line_pro in f_prosite.splitlines():\n",
    "            if line_pro.startswith('>sp|'):\n",
    "                sameID_prosite.append(line_pro)\n",
    "    return sameID_prosite\n",
    "def Similarity_uniprot(final_prosite,final_uniprot):\n",
    "    f_uniprot = open(final_uniprot)\n",
    "    f_uniprot = f_uniprot.read()\n",
    "    sameID_uniprot = []\n",
    "    for line_uni in f_uniprot.splitlines():\n",
    "            if line_uni.startswith('>sp|'):\n",
    "                sameID_uniprot.append(line_uni)\n",
    "    return sameID_uniprot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =================== Main ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_out_prosite, pos_out_uniprot, neg_out = ModifyPosAndNeg(pos_in_prosite,pos_in_uniprot,neg_in)\n",
    "conc_prosite, conc_uniprot, cluster_prosite, cluster_uniprot = ConcatClusterPosAndNeg(pos_out_prosite,pos_out_uniprot,neg_out,cdhit_prosite,cdhit_uniprot)\n",
    "final_prosite, final_uniprot  = FinalFiles(conc_prosite,cluster_prosite,conc_uniprot,cluster_uniprot)\n",
    "sameID = Similarity(final_prosite,final_uniprot)\n",
    "\n",
    "\n",
    "sameID_prosite = Similarity_prosite(final_prosite,final_uniprot)\n",
    "sameID_uniprot = Similarity_uniprot(final_prosite,final_uniprot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Similarity sum up: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2523\n",
      "338\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(sameID))\n",
    "print(len(sameID_prosite)-len(sameID)) # Number of positive proteins obtained from PROSITE\n",
    "print(len(sameID_uniprot)-len(sameID)) # Number of positive proteins obtained from Uniprot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
